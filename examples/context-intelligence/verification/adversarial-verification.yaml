# Adversarial Deep Dive Investigation Recipe v2.2
#
# IMPROVEMENTS OVER v2.1:
# - CONVERGENCE DETECTION: Auto-detect when issues plateau across rounds
#   - Configurable threshold for plateau detection
#   - Tracks issue counts across rounds to identify stagnation
# - SCOPE-AWARE EXIT: Exit early if only scope/completeness issues remain
#   - Factual errors (LSP, logic) block exit
#   - Scope expansion issues (completeness) don't block if factuals clean
# - DYNAMIC AGENT WEIGHTING: Reduced completeness_verifier weight in continuation mode
#   - Scope is already established in continuation mode
#   - Prevents endless "omission" findings that are actually scope expansions
# - CROSS-RUN METRICS: Track metrics across continuations for plateau detection
# - SMART AUTO-APPROVE: Auto-approve when conditions met
#   - Issues below threshold
#   - No critical factual issues
#   - Clean rounds from factual verifiers
#
# IMPROVEMENTS OVER v2.0 (from v2.1):
# - CONTINUATION MODE: Resume verification from a previous document
#
# IMPROVEMENTS OVER v1 (from v2.0):
# - Quick pre-check stage (fail fast on bad inputs)
# - Confidence tagging in investigation phase
# - Broadened LSP verifier (call chains, types, not just line numbers)
# - Added completeness verifier (finds omissions)
# - Real escalation tiers (Standard → Aggressive → Final)
# - Structured verdict blocks (reliable parsing)
# - Cross-visibility between verifiers in later rounds
# - Focus-on-changes mode for rounds 2+
# - Early-exit for consistently clean agents
# - Weighted verifier importance (logic_verifier prioritized)
# - Round timing metrics
# - Per-agent issue attribution in logs
# - Critical issue human checkpoint
#
# Usage:
#
#   FRESH INVESTIGATION (full pipeline):
#   amplifier recipe run adversarial-verification-continuable.yaml \
#     --context topic="How does cancellation work in amplifier-app-cli?" \
#     --context output_dir="./docs/investigations" \
#     --context codebase_paths='["./amplifier-core", "./amplifier-foundation"]'
#
#   CONTINUE FROM PREVIOUS RUN (skip to verification):
#   amplifier recipe run adversarial-verification-continuable.yaml \
#     --context topic="How does cancellation work in amplifier-app-cli?" \
#     --context output_dir="./docs/investigations-continued" \
#     --context continue_from="./docs/investigations/INVESTIGATION_v3.md" \
#     --context starting_version=3
#
#   WITH CONVERGENCE DETECTION (auto-exit on plateau):
#   amplifier recipe run adversarial-verification-continuable.yaml \
#     --context topic="..." \
#     --context output_dir="..." \
#     --context convergence_threshold=2 \
#     --context exit_on_scope_only_issues=true

name: adversarial-verification-continuable
version: "2.2.0"
description: |
  Deep investigation of a technical topic with adversarial verification.
  
  v2.2 Additions (from session analysis):
  - CONVERGENCE DETECTION: Auto-detect issue plateaus across rounds
    - If issue count unchanged for N rounds, trigger early exit
    - Prevents infinite loops when verifiers disagree on scope
  - SCOPE-AWARE EXIT: Exit if only scope issues remain
    - Factual verifiers (LSP, logic) must be clean
    - Scope verifiers (completeness) can have issues without blocking
  - DYNAMIC WEIGHTING: Reduced completeness_verifier weight in continuation mode
    - Fresh mode: completeness_verifier weight = 1.2
    - Continuation mode: completeness_verifier weight = 0.6
    - Scope is already established, focus on factual accuracy
  - SMART AUTO-APPROVE: Auto-approve final_review when conditions met
    - Total issues below auto_approve_threshold
    - No issues from factual verifiers (LSP, logic) in final round
    - Saves human review time for clean documents
  - CROSS-RUN METRICS: Track issue history for plateau detection
  
  v2.1 Additions:
  - CONTINUATION MODE: Resume verification from a previous document
  
  v2.0 Improvements:
  - Pre-check stage validates inputs before expensive investigation
  - Confidence tagging reduces false claims in initial synthesis
  - Real escalation tiers change behavior each round
  - Structured verdicts replace fragile text pattern matching
  - Cross-visibility lets verifiers learn from each other
  - Critical issue checkpoint pauses for human review
  
  Process (Fresh Mode):
  1. Pre-check validates topic and paths (2 min)
  2. Parallel investigation with confidence tagging (15 min)
  3. Synthesis into structured document v1
  4. Adversarial verification rounds with escalation
  5. Human approval of verified document (or auto-approve if conditions met)
  
  Process (Continuation Mode):
  1. Load previous document as starting version
  2. Adversarial verification with reduced completeness weight
  3. Human approval (or auto-approve if conditions met)

# =============================================================================
# CONTEXT VARIABLES (Inputs)
# =============================================================================
context:
  # Required inputs
  topic:
    type: string
    required: true
    description: |
      The question or topic to investigate. Be specific.
      Example: "How does the system prompt get composed for a bundle session?"
  
  output_dir:
    type: string
    required: true
    description: |
      Directory to save investigation documents.
      Will contain: v1.md, v2.md, ..., FINAL.md, verification-log.md, metrics.json
  
  # ==========================================================================
  # CONTINUATION MODE (Skip investigation, resume verification)
  # ==========================================================================
  continue_from:
    type: string
    default: ""
    description: |
      Path to a previously verified document to continue verification from.
      When provided, skips pre_check, initial_investigation, and synthesis stages.
      
      Example: "./docs/investigations/INVESTIGATION_v3.md"
      
      Use this when:
      - You want to run more verification rounds on an existing document
      - Previous verification was interrupted
      - You've manually edited a document and want to re-verify
  
  starting_version:
    type: integer
    default: 1
    description: |
      Version number to assign to the continue_from document.
      Used when continuing from a previous run.
      
      Example: If continue_from is INVESTIGATION_v3.md, set starting_version to 3.
      
      This ensures version numbering continues correctly (v3 → v4 → v5 → FINAL).
  
  # Optional inputs with defaults
  codebase_paths:
    type: array
    default: ["."]
    description: |
      List of paths to investigate. Defaults to current directory.
      Example: ["./amplifier-core", "./amplifier-foundation"]
  
  max_rounds:
    type: integer
    default: 5
    description: |
      Maximum adversarial verification rounds before forcing human review.
      Typical: 3-4 rounds for clean verification.
  
  focus_areas:
    type: array
    default: []
    description: |
      Optional list of specific files, modules, or concepts to focus on.
      Example: ["registry.py", "bundle composition", "context resolution"]
  
  additional_agents:
    type: array
    default: []
    description: |
      Additional agents beyond the core set for investigation phase.
      These are ADDED to the default investigation agents.
      Example: ["amplifier:amplifier-expert", "foundation:security-guardian"]
  
  additional_verifiers:
    type: array
    default: []
    description: |
      Additional verification agents beyond the core set.
      Example: ["foundation:security-guardian"]
  
  investigation_type:
    type: string
    default: "codebase"
    description: |
      Type of investigation. Affects agent prioritization.
      Options: "codebase" | "architecture" | "integration" | "security"
  
  critical_issue_threshold:
    type: integer
    default: 5
    description: |
      If a single round finds this many issues, pause for human checkpoint.
      Set to 0 to disable (never pause mid-verification).
  
  early_exit_clean_rounds:
    type: integer
    default: 2
    description: |
      If an agent is clean for this many consecutive rounds, skip it.
      Optimization to reduce redundant verification work.
  
  # ==========================================================================
  # v2.2: CONVERGENCE DETECTION & SMART EXIT
  # ==========================================================================
  
  convergence_threshold:
    type: integer
    default: 2
    description: |
      Number of consecutive rounds with similar issue counts to detect plateau.
      
      When issues remain roughly constant for this many rounds, the recipe
      will trigger early exit instead of continuing to max_rounds.
      
      Example: If set to 2 and rounds 4, 5, 6 all have ~5 issues, exit after round 6.
      
      Set to 0 to disable convergence detection (always run to max_rounds or clean).
      
      Rationale: Session analysis showed issue counts plateauing when verifiers
      disagree on scope vs factual issues. Detecting this saves time.
  
  convergence_variance:
    type: integer
    default: 2
    description: |
      Allowed variance in issue counts when detecting convergence.
      
      Issues are considered "similar" if within ± this value.
      Example: With variance=2, issue counts of 5, 6, 4 would be considered a plateau.
      
      Lower values = stricter plateau detection (must be nearly identical).
      Higher values = looser detection (treats similar counts as plateau).
  
  exit_on_scope_only_issues:
    type: boolean
    default: true
    description: |
      Exit early if the only remaining issues are scope/completeness type.
      
      When true:
      - If lsp_verifier and logic_verifier are CLEAN
      - But completeness_verifier still has issues
      - Consider the document "factually verified" and exit
      
      Rationale: Session analysis showed completeness_verifier finds "omissions"
      that are actually scope expansions, not factual errors. These create
      infinite loops as the scope keeps growing.
      
      The factual verifiers (LSP, logic) converge quickly because code facts
      are binary (correct or incorrect). Scope is subjective.
  
  # ==========================================================================
  # v2.2: SMART AUTO-APPROVE
  # ==========================================================================
  
  auto_approve_threshold:
    type: integer
    default: 3
    description: |
      Maximum total issues in final round for auto-approval.
      
      If all these conditions are met, skip human review:
      1. Total issues in final round ≤ this threshold
      2. lsp_verifier had 0 issues in final round
      3. logic_verifier had 0 issues in final round
      4. No CRITICAL severity issues
      
      Set to 0 to disable auto-approval (always require human review).
      
      Rationale: When factual verifiers are clean and only minor scope
      suggestions remain, human review adds little value.
  
  auto_approve_clean_factual_rounds:
    type: integer
    default: 1
    description: |
      Number of clean rounds required from factual verifiers for auto-approval.
      
      Factual verifiers: lsp_verifier, logic_verifier
      These verify objective facts (code exists, logic is consistent).
      
      If these verifiers have been clean for N consecutive rounds,
      the document is factually sound and can be auto-approved
      (assuming other auto_approve conditions are met).

  # ==========================================================================
  # INTERNAL: Agent Configurations
  # ==========================================================================
  
  # Core investigation agents (additional_agents extends this)
  investigation_agents:
    - name: "explorer"
      agent: "foundation:explorer"
      focus: "code survey and data flow"
      weight: 1.0
      mission: |
        Conduct a comprehensive survey of the codebase.
        Find entry points, key files, data flow, and dependencies.
        Map the complete flow from trigger to completion.
    - name: "lsp"
      agent: "lsp-python:python-code-intel"
      focus: "precise call chains, types, and line numbers"
      weight: 1.0
      mission: |
        Use LSP tools to trace precise call hierarchy and type information.
        Verify exact line numbers, function signatures, and call relationships.
        Use hover for type info, goToDefinition for locations, call hierarchy for flow.
    - name: "architect"
      agent: "foundation:zen-architect"
      focus: "design patterns and architecture"
      weight: 1.0
      mission: |
        Analyze architectural design and patterns.
        Identify module boundaries, contracts, and composition model.
        Note design decisions and their implications.
  
  # Verification agents with weights (higher = more important)
  # NOTE: In continuation mode, completeness_verifier weight is reduced dynamically
  verification_agents:
    - name: "lsp_verifier"
      agent: "lsp-python:python-code-intel"
      focus: "code accuracy and call chains"
      weight: 1.0
      is_factual: true  # v2.2: Mark as factual verifier
      mission: |
        PROVE THIS DOCUMENT WRONG using semantic code analysis:
        
        1. **Line numbers & paths**: Verify every file:line reference exists
        2. **Function signatures**: Check parameter names, types, return values
        3. **Call chains**: Verify claimed A→B→C flows with incomingCalls/outgoingCalls
        4. **Type claims**: Use hover to verify stated types match actual
        5. **Missing steps**: Use call hierarchy to find omitted intermediate calls
    - name: "flow_verifier"
      agent: "foundation:explorer"
      focus: "flow accuracy and completeness"
      weight: 1.0
      is_factual: false
      mission: |
        PROVE THE FLOW DESCRIPTION WRONG. Check:
        - Sequence of operations (order matters!)
        - Missing steps in the flow
        - Dependencies and initialization order
        - Data transformations at each step
        - Error handling paths
    - name: "logic_verifier"
      agent: "foundation:bug-hunter"
      focus: "logical errors and omissions"
      weight: 1.5  # Higher weight - historically finds most issues
      is_factual: true  # v2.2: Mark as factual verifier
      mission: |
        FIND LOGICAL ERRORS OR OMISSIONS. This is the most critical verifier.
        
        Check for:
        - Inconsistencies between sections
        - Missing edge cases and error paths
        - Incorrect assumptions about behavior
        - Ambiguous or misleading statements
        - Claims that contradict each other
        - Logical leaps without evidence
    - name: "completeness_verifier"
      agent: "foundation:explorer"
      focus: "missing information"
      weight: 1.2  # v2.2: Reduced to 0.6 in continuation mode (see verification_loop)
      is_factual: false  # v2.2: Mark as scope verifier (not factual)
      continuation_weight: 0.6  # v2.2: Lower weight in continuation mode
      mission: |
        Find what the document OMITS. The most dangerous errors are missing pieces.
        
        1. Search for related files NOT mentioned in the document
        2. Find sibling functions/classes that should be covered
        3. Identify config files, constants, or env vars that affect behavior
        4. Check for error handling paths not documented
        5. Look for alternative code paths (if/else branches)
        
        Report: "OMISSION: Document doesn't mention [X] which affects [Y]"
        
        ⚠️ v2.2 NOTE: In continuation mode, your weight is reduced.
        Focus on CRITICAL omissions only, not scope expansions.
        The document scope is already established - don't suggest adding
        tangential topics. Only flag omissions that would make the
        existing content misleading or incomplete.
  
  # Escalation tier definitions
  escalation_tiers:
    standard:
      rounds: [1, 2]
      parallel: true
      require_evidence: false
      cross_visibility: false
      description: "Standard verification - catch obvious errors"
    aggressive:
      rounds: [3, 4]
      parallel: true
      require_evidence: true
      cross_visibility: true
      description: "Aggressive verification - subtle errors, edge cases, patterns"
    final:
      rounds: [5]
      parallel: false
      require_evidence: true
      cross_visibility: true
      use_additional_agents: true
      description: "Final verification - any remaining doubt, fresh perspectives"

# =============================================================================
# STAGES
# =============================================================================
stages:
  # ===========================================================================
  # STAGE 0: PRE-CHECK (Quick Validation)
  # SKIPPED in continuation mode
  # ===========================================================================
  - name: pre_check
    description: |
      Quick validation that the topic is investigable and inputs are valid.
      Fails fast before expensive investigation if inputs are bad.
      
      SKIPPED when continue_from is provided (continuation mode).
    approval_required: false
    condition: "{{continue_from}} == ''"
    
    steps:
      - id: validate_inputs
        agent: self
        timeout: 120  # 2 minutes max
        prompt: |
          # Quick Pre-Check (Max 2 minutes)
          
          Before full investigation, validate that this request is investigable.
          
          ## Inputs to Validate
          - **Topic**: {{topic}}
          - **Codebase paths**: {{codebase_paths}}
          - **Focus areas**: {{focus_areas}}
          - **Investigation type**: {{investigation_type}}
          
          ## Validation Checks
          
          Perform these checks quickly:
          
          ### 1. Paths Exist
          Check that each path in codebase_paths exists:
          ```bash
          for path in {{codebase_paths}}; do
            test -e "$path" && echo "✓ $path exists" || echo "✗ $path NOT FOUND"
          done
          ```
          
          ### 2. Topic Clarity
          Is the topic a clear, answerable question?
          - ✓ Good: "How does session cancellation propagate to running agents?"
          - ✗ Bad: "Explain everything about sessions"
          - ✗ Bad: "Fix the bug" (no question)
          
          ### 3. Scope Sanity
          - Is this too broad? (Would require 50+ page document)
          - Is this too narrow? (Answer is trivial)
          - Is this actually multiple questions? (Should be split)
          
          ### 4. Relevant Code Exists
          Quick grep for keywords from the topic in the codebase:
          - Extract 3-5 key terms from the topic
          - Search for them in the codebase
          - At least some should have matches
          
          ## Output Format
          
          You MUST output this exact block at the end:
          
          ```precheck
          PATHS_VALID: [true|false]
          TOPIC_CLEAR: [true|false]
          SCOPE_OK: [true|false]
          RELEVANT_CODE_FOUND: [true|false]
          PROCEED: [true|false]
          ESTIMATED_COMPLEXITY: [low|medium|high]
          NOTES: [any concerns or suggestions]
          ```
          
          If PROCEED is false, explain what's wrong and suggest fixes.
          Be helpful - if the topic just needs minor rewording, suggest it.
        output: "precheck_result"
      
      - id: check_proceed
        agent: self
        prompt: |
          # Evaluate Pre-Check Result
          
          Pre-check output:
          {{precheck_result}}
          
          Extract the PROCEED value from the precheck block.
          
          If PROCEED: false, output:
          ```
          ❌ PRE-CHECK FAILED
          
          [Extract and display the NOTES explaining what's wrong]
          
          Please fix the inputs and try again.
          ```
          
          If PROCEED: true, output:
          ```
          ✅ PRE-CHECK PASSED
          
          Proceeding with investigation...
          - Complexity: [ESTIMATED_COMPLEXITY value]
          - Notes: [any notes]
          ```
        output: "proceed_decision"

  # ===========================================================================
  # STAGE 1: INITIAL INVESTIGATION
  # SKIPPED in continuation mode
  # ===========================================================================
  - name: initial_investigation
    description: |
      Parallel multi-agent investigation of the topic.
      Each agent brings a different perspective and toolset.
      Results are confidence-tagged before synthesis.
      
      SKIPPED when continue_from is provided (continuation mode).
    approval_required: false
    condition: "{{continue_from}} == ''"
    
    steps:
      - id: parallel_investigation
        agent: self
        prompt: |
          # Parallel Investigation Orchestrator
          
          You are orchestrating a multi-agent investigation. Dispatch multiple agents
          IN PARALLEL and collect their findings.
          
          ## Topic to Investigate
          {{topic}}
          
          ## Scope
          - Codebase paths: {{codebase_paths}}
          - Focus areas: {{focus_areas}}
          - Investigation type: {{investigation_type}}
          
          ## Investigation Agents to Dispatch
          
          ### Core Agents (always used):
          {{investigation_agents}}
          
          ### Additional Agents (user-specified):
          {{additional_agents}}
          
          ## Instructions
          
          For EACH agent (core + additional), create a delegate() call with:
          
          1. **agent**: The agent identifier (e.g., "foundation:explorer")
          2. **instruction**: Include:
             - The topic: {{topic}}
             - Their role name and focus area
             - Their specific mission
             - The scope (codebase_paths, focus_areas)
             - Deliverable requirements (below)
          
          ## Required Deliverables (include in each instruction)
          
          Tell each agent to provide findings in this format:
          
          ```
          ## [Agent Name] Findings
          
          ### Key Discoveries
          [Numbered list of findings]
          
          ### File References
          | File | Lines | What |
          |------|-------|------|
          | path/to/file.py | 45-67 | Description |
          
          ### Code Flow
          [If applicable, describe the flow with steps]
          
          ### Confidence Markers
          For EACH factual claim, mark confidence:
          - [HIGH] Multiple sources confirm OR LSP-verified
          - [MEDIUM] Single source, plausible but not cross-verified
          - [LOW] Inferred, uncertain, or couldn't fully verify
          
          ### Uncertainties
          [List anything they couldn't verify or aren't sure about]
          ```
          
          ## Execution
          
          1. Launch ALL delegate() calls in a SINGLE function_calls block
          2. Wait for all agents to complete
          3. Collect and organize their findings
          4. Return consolidated report with confidence markers preserved
          
          ## Timing
          
          Record start time before dispatching, end time after all complete.
          Include in output:
          ```
          Investigation Timing:
          - Started: [timestamp]
          - Completed: [timestamp]
          - Duration: [seconds]
          - Agents dispatched: [count]
          ```
        output: "investigation_findings"
        timeout: 900  # 15 minutes

      - id: confidence_tagging
        agent: self
        prompt: |
          # Confidence Consolidation Pass
          
          Review the investigation findings and ensure all claims are tagged.
          
          ## Raw Findings
          {{investigation_findings}}
          
          ## Your Task
          
          1. Scan for any claims WITHOUT confidence tags
          2. Add tags based on evidence:
             - [HIGH]: Claim appears in multiple agent outputs OR has LSP evidence
             - [MEDIUM]: Single agent found it, seems plausible
             - [LOW]: Inferred, speculative, or agents disagreed
          
          3. Flag CONFLICTS where agents disagree:
             ```
             ⚠️ CONFLICT: [topic]
             - Agent A says: [claim]
             - Agent B says: [different claim]
             - Resolution needed in synthesis
             ```
          
          4. Create a summary of confidence distribution:
             ```
             Confidence Summary:
             - HIGH confidence claims: [count]
             - MEDIUM confidence claims: [count]
             - LOW confidence claims: [count]
             - CONFLICTS to resolve: [count]
             ```
          
          Output the tagged findings with the summary appended.
        output: "tagged_findings"

  # ===========================================================================
  # STAGE 2: SYNTHESIS
  # SKIPPED in continuation mode
  # ===========================================================================
  - name: synthesis
    description: |
      Combine investigation findings into a structured document (v1).
      Respects confidence tags - LOW confidence items noted as needing verification.
      
      SKIPPED when continue_from is provided (continuation mode).
    approval_required: false
    condition: "{{continue_from}} == ''"
    
    steps:
      - id: create_v1_document
        agent: foundation:zen-architect
        prompt: |
          # Synthesize Investigation Findings
          
          ## Topic
          {{topic}}
          
          ## Input Findings (with confidence tags)
          {{tagged_findings}}
          
          ## Your Task
          
          Create a comprehensive, well-structured document that:
          
          1. **Synthesizes** all HIGH and MEDIUM confidence findings
          2. **Notes LOW confidence items** as "needs verification"
          3. **Resolves conflicts** - pick most evidenced position, note alternatives
          4. **Includes precise references** (file paths, line numbers)
          5. **Uses diagrams** (ASCII) for complex flows
          
          ## Document Structure
          
          Use this EXACT structure:
          
          ```markdown
          # [Descriptive Title for {{topic}}]
          
          **Version**: 1
          **Status**: Initial synthesis (pending verification)
          **Confidence**: [% HIGH] high, [% MEDIUM] medium, [% LOW] low-confidence claims
          **Date**: [YYYY-MM-DD HH:MM]
          
          ## Executive Summary
          [2-3 sentence answer to the topic question]
          
          ## Overview
          [High-level explanation - what, why, context]
          
          ## Complete Flow
          
          ### Flow Diagram
          ```
          [ASCII diagram showing the overall flow]
          ```
          
          ### Step-by-Step
          1. **Step Name** (file.py:L##)
             - What happens
             - Why it matters
          
          2. **Next Step** (file.py:L##)
             ...
          
          ## Key Components
          
          | Component | File | Lines | Confidence | Description |
          |-----------|------|-------|------------|-------------|
          | ... | ... | ... | HIGH/MED/LOW | ... |
          
          ## Technical Details
          [Implementation specifics, edge cases, important nuances]
          
          ## Needs Verification
          [List all LOW confidence claims that verifiers should check]
          - [ ] Claim 1 - why uncertain
          - [ ] Claim 2 - why uncertain
          
          ## Resolved Conflicts
          [If any conflicts existed, how they were resolved]
          
          ## Open Questions
          [Any questions the investigation couldn't answer]
          ```
          
          ## Critical Requirements
          - Preserve confidence tags from source material
          - Every file path must be exact
          - Every line number must be precise
          - Flag anything uncertain in "Needs Verification"
        output: "document_v1"
      
      - id: save_v1
        type: bash
        command: |
          # Pre-compute timestamp to avoid HEREDOC issues
          TIMESTAMP=$(date -Iseconds)
          
          mkdir -p "{{output_dir}}"
          
          # Save v1 document
          cat > "{{output_dir}}/INVESTIGATION_v1.md" << 'DOCUMENT_END'
          {{document_v1}}
          DOCUMENT_END
          
          # Initialize verification log
          cat > "{{output_dir}}/verification-log.md" << LOGEOF
          # Verification Log: {{topic}}
          
          ## Investigation Overview
          - **Topic**: {{topic}}
          - **Mode**: Fresh investigation
          - **Started**: ${TIMESTAMP}
          - **Max rounds**: {{max_rounds}}
          - **Critical issue threshold**: {{critical_issue_threshold}}
          - **Early exit after clean rounds**: {{early_exit_clean_rounds}}
          - **Convergence threshold**: {{convergence_threshold}} rounds (v2.2)
          - **Exit on scope-only issues**: {{exit_on_scope_only_issues}} (v2.2)
          - **Auto-approve threshold**: {{auto_approve_threshold}} (v2.2)
          
          ## Agent Configuration
          
          ### Investigation Agents
          - explorer (foundation:explorer)
          - lsp (lsp-python:python-code-intel)
          - architect (foundation:zen-architect)
          - Additional: {{additional_agents}}
          
          ### Verification Agents
          - lsp_verifier (weight: 1.0, factual: ✓)
          - flow_verifier (weight: 1.0)
          - logic_verifier (weight: 1.5, factual: ✓) ⭐ Primary
          - completeness_verifier (weight: 1.2, scope-based)
          - Additional: {{additional_verifiers}}
          
          ## Round History
          
          ### Initial Synthesis (v1)
          - **Created**: ${TIMESTAMP}
          - **Status**: Pending adversarial verification
          
          ---
          LOGEOF
          
          # Initialize metrics file with v2.2 fields
          cat > "{{output_dir}}/metrics.json" << METRICSEOF
          {
            "topic": "{{topic}}",
            "mode": "fresh",
            "version": "2.2.0",
            "started": "${TIMESTAMP}",
            "config": {
              "max_rounds": {{max_rounds}},
              "convergence_threshold": {{convergence_threshold}},
              "convergence_variance": {{convergence_variance}},
              "exit_on_scope_only_issues": {{exit_on_scope_only_issues}},
              "auto_approve_threshold": {{auto_approve_threshold}},
              "early_exit_clean_rounds": {{early_exit_clean_rounds}}
            },
            "investigation_phase": {},
            "rounds": [],
            "issue_history": [],
            "convergence_detected": false,
            "scope_only_exit": false,
            "auto_approved": false,
            "agent_performance": {
              "lsp_verifier": {"issues_found": 0, "clean_rounds": 0, "is_factual": true},
              "flow_verifier": {"issues_found": 0, "clean_rounds": 0, "is_factual": false},
              "logic_verifier": {"issues_found": 0, "clean_rounds": 0, "is_factual": true},
              "completeness_verifier": {"issues_found": 0, "clean_rounds": 0, "is_factual": false}
            }
          }
          METRICSEOF
          
          echo "Created v1 document, verification log, and metrics in {{output_dir}}"

  # ===========================================================================
  # STAGE 3: ADVERSARIAL VERIFICATION (Iterative with Escalation)
  # Always runs - handles both fresh and continuation modes
  # ===========================================================================
  - name: adversarial_verification
    description: |
      Iterative adversarial verification with real escalation tiers.
      - Rounds 1-2: Standard (parallel, obvious errors)
      - Rounds 3-4: Aggressive (parallel, cross-visibility, evidence required)
      - Round 5+: Final (sequential, fresh agents, any doubt)
      
      v2.2 Enhancements:
      - Convergence detection: Exit if issues plateau for N rounds
      - Scope-aware exit: Exit if only completeness issues remain
      - Dynamic weighting: Reduced completeness_verifier weight in continuation mode
      
      In continuation mode, starts from the provided document and version number.
    approval_required: false
    
    steps:
      # Setup step for continuation mode - copies previous document and initializes logs
      - id: setup_continuation
        type: bash
        condition: "{{continue_from}} != ''"
        command: |
          # CONTINUATION MODE: Copy previous document to output_dir as starting version
          TIMESTAMP=$(date -Iseconds)
          
          echo "═══════════════════════════════════════════════════════════════════"
          echo "  CONTINUATION MODE ACTIVE (v2.2)"
          echo "═══════════════════════════════════════════════════════════════════"
          echo ""
          echo "Source document: {{continue_from}}"
          echo "Starting version: {{starting_version}}"
          echo "Output directory: {{output_dir}}"
          echo ""
          echo "v2.2 Enhancements Active:"
          echo "  • Convergence threshold: {{convergence_threshold}} rounds"
          echo "  • Exit on scope-only issues: {{exit_on_scope_only_issues}}"
          echo "  • Auto-approve threshold: {{auto_approve_threshold}}"
          echo "  • Completeness verifier weight: 0.6 (reduced from 1.2)"
          echo ""
          
          # Validate source document exists
          if [ ! -f "{{continue_from}}" ]; then
            echo "ERROR: Source document not found: {{continue_from}}"
            exit 1
          fi
          
          mkdir -p "{{output_dir}}"
          
          # Copy the continue_from document as the starting version
          cp "{{continue_from}}" "{{output_dir}}/INVESTIGATION_v{{starting_version}}.md"
          
          echo "✓ Copied source document to {{output_dir}}/INVESTIGATION_v{{starting_version}}.md"
          
          # Initialize verification log for continuation
          cat > "{{output_dir}}/verification-log.md" << LOGEOF
          # Verification Log: {{topic}}
          
          ## Investigation Overview
          - **Topic**: {{topic}}
          - **Mode**: CONTINUATION from previous run (v2.2)
          - **Source document**: {{continue_from}}
          - **Started**: ${TIMESTAMP}
          - **Starting version**: v{{starting_version}}
          - **Max rounds**: {{max_rounds}}
          - **Critical issue threshold**: {{critical_issue_threshold}}
          - **Early exit after clean rounds**: {{early_exit_clean_rounds}}
          
          ## v2.2 Convergence Settings
          - **Convergence threshold**: {{convergence_threshold}} rounds
          - **Convergence variance**: ±{{convergence_variance}} issues
          - **Exit on scope-only issues**: {{exit_on_scope_only_issues}}
          - **Auto-approve threshold**: {{auto_approve_threshold}}
          
          ## Agent Configuration (Continuation Mode Weights)
          
          ### Verification Agents
          - lsp_verifier (weight: 1.0, factual: ✓)
          - flow_verifier (weight: 1.0)
          - logic_verifier (weight: 1.5, factual: ✓) ⭐ Primary
          - completeness_verifier (weight: **0.6** ← reduced in continuation mode)
          - Additional: {{additional_verifiers}}
          
          ## Round History
          
          ### Continuation Start (v{{starting_version}})
          - **Source**: {{continue_from}}
          - **Loaded**: ${TIMESTAMP}
          - **Status**: Resuming adversarial verification with v2.2 enhancements
          
          ---
          LOGEOF
          
          echo "✓ Created verification log"
          
          # Initialize metrics file for continuation with v2.2 fields
          cat > "{{output_dir}}/metrics.json" << METRICSEOF
          {
            "topic": "{{topic}}",
            "mode": "continuation",
            "version": "2.2.0",
            "continue_from": "{{continue_from}}",
            "starting_version": {{starting_version}},
            "started": "${TIMESTAMP}",
            "config": {
              "max_rounds": {{max_rounds}},
              "convergence_threshold": {{convergence_threshold}},
              "convergence_variance": {{convergence_variance}},
              "exit_on_scope_only_issues": {{exit_on_scope_only_issues}},
              "auto_approve_threshold": {{auto_approve_threshold}},
              "early_exit_clean_rounds": {{early_exit_clean_rounds}},
              "continuation_completeness_weight": 0.6
            },
            "rounds": [],
            "issue_history": [],
            "convergence_detected": false,
            "scope_only_exit": false,
            "auto_approved": false,
            "agent_performance": {
              "lsp_verifier": {"issues_found": 0, "clean_rounds": 0, "is_factual": true},
              "flow_verifier": {"issues_found": 0, "clean_rounds": 0, "is_factual": false},
              "logic_verifier": {"issues_found": 0, "clean_rounds": 0, "is_factual": true},
              "completeness_verifier": {"issues_found": 0, "clean_rounds": 0, "is_factual": false, "weight": 0.6}
            }
          }
          METRICSEOF
          
          echo "✓ Created metrics file"
          echo ""
          echo "Ready to begin adversarial verification from v{{starting_version}}"
        output: "continuation_setup_result"

      - id: verification_loop
        agent: self
        prompt: |
          # Adversarial Verification Orchestrator v2.2
          
          You are orchestrating iterative adversarial verification with REAL escalation
          and v2.2 CONVERGENCE DETECTION.
          
          ## Context
          - **Topic**: {{topic}}
          - **Output directory**: {{output_dir}}
          - **Max rounds**: {{max_rounds}}
          - **Critical issue threshold**: {{critical_issue_threshold}} (pause for human if exceeded)
          - **Early exit clean rounds**: {{early_exit_clean_rounds}}
          
          ## v2.2 CONVERGENCE SETTINGS
          - **Convergence threshold**: {{convergence_threshold}} rounds (exit if issues plateau)
          - **Convergence variance**: ±{{convergence_variance}} issues (for plateau detection)
          - **Exit on scope-only issues**: {{exit_on_scope_only_issues}}
          - **Auto-approve threshold**: {{auto_approve_threshold}} (skip human review if met)
          
          ## MODE CHECK
          
          {% if continue_from != '' %}
          ═══════════════════════════════════════════════════════════════════════════
          ⚠️  CONTINUATION MODE ACTIVE (v2.2)
          ═══════════════════════════════════════════════════════════════════════════
          
          - **Source document**: {{continue_from}}
          - **Starting version**: {{starting_version}}
          - **Initial document**: {{output_dir}}/INVESTIGATION_v{{starting_version}}.md
          
          ### CONTINUATION MODE WEIGHT ADJUSTMENTS
          
          In continuation mode, the document scope is ALREADY ESTABLISHED.
          completeness_verifier findings are often scope expansions, not errors.
          
          **DYNAMIC WEIGHT ADJUSTMENT:**
          - completeness_verifier weight: 0.6 (reduced from 1.2)
          - This means completeness issues count less toward totals
          - Prevents infinite loops from scope expansion suggestions
          
          IMPORTANT: Initialize current_version to {{starting_version}} (NOT 1).
          
          ═══════════════════════════════════════════════════════════════════════════
          {% else %}
          Mode: Fresh investigation (starting from v1)
          {% endif %}
          
          ## Verification Agents
          {{verification_agents}}
          
          ## Additional Verifiers (user-specified)
          {{additional_verifiers}}
          
          ## Escalation Tiers
          {{escalation_tiers}}
          
          ## State Tracking
          
          You MUST maintain this state across rounds:
          
          ```state
          current_round: 1
          current_version: {% if continue_from != '' %}{{starting_version}}{% else %}1{% endif %}
          total_issues_fixed: 0
          agent_clean_streaks: {
            "lsp_verifier": 0,
            "flow_verifier": 0,
            "logic_verifier": 0,
            "completeness_verifier": 0
          }
          # v2.2: Track factual vs scope issues separately
          agent_is_factual: {
            "lsp_verifier": true,
            "flow_verifier": false,
            "logic_verifier": true,
            "completeness_verifier": false
          }
          # v2.2: Issue history for convergence detection
          issue_history: []  # List of total issues per round
          factual_issue_history: []  # List of factual issues per round
          scope_issue_history: []  # List of scope issues per round
          previous_round_findings: {}
          round_timings: []
          # v2.2: Exit condition tracking
          convergence_detected: false
          scope_only_exit: false
          auto_approve_eligible: false
          ```
          
          ## Main Loop (up to {{max_rounds}} rounds)
          
          ### For Each Round N:
          
          **Step 1: Determine Escalation Tier**
          
          ```
          if N in [1, 2]: tier = "standard"
          elif N in [3, 4]: tier = "aggressive"  
          else: tier = "final"
          ```
          
          **Step 2: Select Active Verifiers**
          
          Skip agents with clean_streak >= {{early_exit_clean_rounds}}:
          ```python
          active_verifiers = []
          for agent in verification_agents:
            if agent_clean_streaks[agent.name] < {{early_exit_clean_rounds}}:
              active_verifiers.append(agent)
            else:
              log(f"Skipping {agent.name} - clean for {agent_clean_streaks[agent.name]} rounds")
          ```
          
          Exception: logic_verifier is NEVER skipped (highest weight, finds most issues).
          
          **Step 2.5: v2.2 - Apply Dynamic Weights (Continuation Mode)**
          
          {% if continue_from != '' %}
          In continuation mode, adjust completeness_verifier weight:
          ```python
          agent_weights = {
            "lsp_verifier": 1.0,
            "flow_verifier": 1.0,
            "logic_verifier": 1.5,
            "completeness_verifier": 0.6  # REDUCED from 1.2
          }
          ```
          
          When calculating weighted issues:
          ```python
          weighted_issues = sum(
            agent_issues[name] * agent_weights[name]
            for name in agent_issues
          )
          ```
          {% endif %}
          
          **Step 3: Read Current Document**
          
          Read `{{output_dir}}/INVESTIGATION_v{current_version}.md`
          
          **Step 4: Build Verifier Instructions**
          
          For EACH active verifier, build instruction based on tier:
          
          #### Standard Tier (Rounds 1-2)
          ```
          ADVERSARIAL VERIFICATION - Round {N} (Standard)
          
          Your mission: {agent.mission}
          Focus: {agent.focus}
          
          Document: {{output_dir}}/INVESTIGATION_v{current_version}.md
          
          For each claim in your focus area:
          - ✅ VERIFIED: [claim] - Evidence: [what you checked]
          - ❌ INCORRECT: [claim] - Actual: [correct info] - Source: [file:line]
          
          You MUST end with this verdict block:
          
          ```verdict
          AGENT: {agent.name}
          ISSUES_FOUND: [integer]
          ISSUE_LIST: [semicolon-separated list of issues, or "none"]
          ISSUE_TYPE: [FACTUAL|SCOPE|MIXED]  # v2.2: Classify issue type
          CONFIDENCE: [HIGH|MEDIUM|LOW]
          VERDICT: [CLEAN|ISSUES]
          ```
          ```
          
          #### Aggressive Tier (Rounds 3-4)
          ```
          ADVERSARIAL VERIFICATION - Round {N} (Aggressive)
          
          ESCALATION: Evidence REQUIRED for every claim. Look for PATTERNS.
          
          Your mission: {agent.mission}
          Focus: {agent.focus}
          
          Document: {{output_dir}}/INVESTIGATION_v{current_version}.md
          
          ## Previous Round Context
          Other verifiers found these issues last round:
          {previous_round_findings}
          
          Look for SIMILAR PATTERNS to what they found.
          
          ## Requirements
          - EVERY verification must cite file:line evidence
          - Check for patterns similar to previous issues
          - Look for subtle errors, edge cases, implicit assumptions
          
          For each claim:
          - ✅ VERIFIED: [claim] - Evidence: [file:line proof]
          - ❌ INCORRECT: [claim] - Actual: [correct info] - Source: [file:line]
          
          ```verdict
          AGENT: {agent.name}
          ISSUES_FOUND: [integer]
          ISSUE_LIST: [semicolon-separated list]
          ISSUE_TYPE: [FACTUAL|SCOPE|MIXED]
          CONFIDENCE: [HIGH|MEDIUM|LOW]
          VERDICT: [CLEAN|ISSUES]
          ```
          ```
          
          #### Final Tier (Round 5+)
          ```
          ADVERSARIAL VERIFICATION - Round {N} (FINAL)
          
          ⚠️ THIS IS THE FINAL CHECK. After this, the document ships.
          
          Your mission: {agent.mission}
          Focus: {agent.focus}
          
          Document: {{output_dir}}/INVESTIGATION_v{current_version}.md
          
          ## All Previous Findings
          {all_previous_findings}
          
          ## Your Charge
          If you have ANY doubt about ANY claim, flag it now.
          This is your last chance to catch errors.
          
          Be thorough. Be paranoid. Question everything.
          
          ```verdict
          AGENT: {agent.name}
          ISSUES_FOUND: [integer]
          ISSUE_LIST: [semicolon-separated list]
          ISSUE_TYPE: [FACTUAL|SCOPE|MIXED]
          CONFIDENCE: [HIGH|MEDIUM|LOW]
          VERDICT: [CLEAN|ISSUES]
          ```
          ```
          
          **Step 5: Dispatch Verifiers**
          
          - Standard/Aggressive: Dispatch ALL active verifiers IN PARALLEL
          - Final: Dispatch SEQUENTIALLY (each sees previous results)
          
          Record start time before dispatch.
          
          **Step 6: Parse Verdicts**
          
          For EACH agent response, extract the verdict block:
          
          ```python
          # Parse verdict block
          verdict_match = re.search(r'```verdict\n(.*?)\n```', response, re.DOTALL)
          if not verdict_match:
              # Missing verdict = treat as ISSUES, force clarification
              agent_result = {"verdict": "ISSUES", "issues_found": -1, "needs_rerun": True}
          else:
              # Parse structured fields including ISSUE_TYPE
              agent_result = parse_verdict_block(verdict_match.group(1))
          ```
          
          **Step 7: Aggregate Results with v2.2 Classification**
          
          ```python
          round_issues = 0
          factual_issues = 0  # v2.2: Track separately
          scope_issues = 0    # v2.2: Track separately
          agent_issues = {}
          
          for agent, result in results.items():
              agent_issues[agent] = result["issues_found"]
              round_issues += result["issues_found"]
              
              # v2.2: Classify issues
              if agent_is_factual[agent]:
                  factual_issues += result["issues_found"]
              else:
                  scope_issues += result["issues_found"]
              
              if result["verdict"] == "CLEAN":
                  agent_clean_streaks[agent] += 1
              else:
                  agent_clean_streaks[agent] = 0
          
          # v2.2: Record issue history for convergence detection
          issue_history.append(round_issues)
          factual_issue_history.append(factual_issues)
          scope_issue_history.append(scope_issues)
          
          round_is_clean = (round_issues == 0) and all(r["verdict"] == "CLEAN" for r in results.values())
          
          # v2.2: Check for factual-only clean (scope issues remaining)
          factual_clean = (factual_issues == 0)
          ```
          
          Record end time, calculate duration.
          
          **Step 7.5: v2.2 - Convergence Detection**
          
          After aggregating results, check for convergence:
          
          ```python
          # v2.2: Convergence detection
          if {{convergence_threshold}} > 0 and len(issue_history) >= {{convergence_threshold}}:
              recent_issues = issue_history[-{{convergence_threshold}}:]
              avg_issues = sum(recent_issues) / len(recent_issues)
              
              # Check if all recent rounds are within variance of average
              converged = all(
                  abs(count - avg_issues) <= {{convergence_variance}}
                  for count in recent_issues
              )
              
              if converged and round_issues > 0:
                  convergence_detected = True
                  log(f"⚠️ CONVERGENCE DETECTED: Issues plateaued at ~{avg_issues} for {{{convergence_threshold}}} rounds")
          ```
          
          **Step 7.6: v2.2 - Scope-Only Exit Check**
          
          ```python
          # v2.2: Check if only scope issues remain
          if {{exit_on_scope_only_issues}} and factual_clean and scope_issues > 0:
              scope_only_exit = True
              log(f"✅ SCOPE-ONLY EXIT: Factual verifiers clean, {scope_issues} scope issues remaining")
              log("Document is factually verified. Scope suggestions are optional.")
          ```
          
          **Step 7.7: v2.2 - Auto-Approve Eligibility Check**
          
          ```python
          # v2.2: Check auto-approve eligibility
          if {{auto_approve_threshold}} > 0:
              auto_approve_eligible = (
                  round_issues <= {{auto_approve_threshold}} and
                  agent_issues.get("lsp_verifier", 0) == 0 and
                  agent_issues.get("logic_verifier", 0) == 0 and
                  agent_clean_streaks.get("lsp_verifier", 0) >= {{auto_approve_clean_factual_rounds}} and
                  agent_clean_streaks.get("logic_verifier", 0) >= {{auto_approve_clean_factual_rounds}}
              )
              if auto_approve_eligible:
                  log(f"✅ AUTO-APPROVE ELIGIBLE: {round_issues} issues, factual verifiers clean")
          ```
          
          **Step 8: Critical Issue Checkpoint**
          
          If round_issues >= {{critical_issue_threshold}} AND {{critical_issue_threshold}} > 0:
          ```
          ⚠️ CRITICAL ISSUE CHECKPOINT
          
          Round {N} found {round_issues} issues, exceeding threshold of {{critical_issue_threshold}}.
          
          Issues by agent:
          {agent_issues breakdown}
          
          Issue details:
          {issue_list from verdicts}
          
          This may indicate fundamental problems with the investigation.
          Pausing for human review before continuing.
          
          Options:
          1. Continue with corrections
          2. Restart investigation with refined focus
          3. Abort and investigate manually
          ```
          
          **Step 9a: If ISSUES Found (but no early exit triggered)**
          
          Check for v2.2 early exit conditions FIRST:
          
          ```python
          # v2.2: Check exit conditions
          if convergence_detected:
              # Plateau detected - exit with warning
              goto step_9c_with_convergence_warning
          
          if scope_only_exit:
              # Only scope issues - document is factually verified
              goto step_9b_clean_with_scope_note
          ```
          
          If no early exit:
          1. Collect all issues with agent attribution
          2. Create corrected document fixing ALL issues
          3. Increment version: Save as `{{output_dir}}/INVESTIGATION_v{current_version+1}.md`
          4. Update verification log with per-agent attribution and v2.2 tracking:
             
             ```markdown
             ### Round {N} - {tier} Tier - Issues Found
             - **Duration**: {seconds}s
             - **Active verifiers**: {count} ({list skipped if any})
             - **Issues by agent**:
               - lsp_verifier: {count} issues (factual)
               - flow_verifier: {count} issues
               - logic_verifier: {count} issues (factual) ⭐
               - completeness_verifier: {count} issues (scope)
             - **Total issues**: {round_issues}
             - **Factual issues**: {factual_issues}
             - **Scope issues**: {scope_issues}
             - **Issue history**: {issue_history}
             - **Convergence check**: {converged status}
             - **Corrections made**:
               - [{agent}] {issue}: {correction}
             - **New version**: v{current_version+1}
             ```
          
          5. Update metrics.json with round data and v2.2 fields
          6. Store findings for cross-visibility: previous_round_findings = current_findings
          7. Increment current_version
          8. Continue to round N+1
          
          **Step 9b: If ALL CLEAN (or scope-only exit)**
          
          1. Verification complete!
          2. Read current document
          3. Add "## Verification History" section summarizing all rounds
          4. If scope_only_exit, add note:
             ```markdown
             > ℹ️ **Note**: Document verified as factually accurate. 
             > Remaining scope suggestions ({scope_issues}) were not applied
             > as the document scope is considered complete.
             ```
          5. Save as `{{output_dir}}/INVESTIGATION_FINAL.md`
          6. Update verification log:
             
             ```markdown
             ### Round {N} - ALL CLEAN ✅ {or "SCOPE-ONLY EXIT ✅" if applicable}
             - **Duration**: {seconds}s
             - **All {count} active agents**: No issues found {or "No factual issues"}
             - **Document verified after {N} rounds**
             - **v2.2 Exit condition**: {CLEAN | SCOPE_ONLY | CONVERGENCE}
             - **Auto-approve eligible**: {yes/no}
             
             ## Final Summary
             - **Total rounds**: {N}
             - **Total issues fixed**: {total_issues_fixed}
             - **Issues by agent (all rounds)**:
               - logic_verifier: {total} (factual)
               - lsp_verifier: {total} (factual)
               - flow_verifier: {total}
               - completeness_verifier: {total} (scope)
             - **Factual issues fixed**: {sum of factual}
             - **Scope issues fixed**: {sum of scope}
             - **Agents early-exited**: {list}
             - **Total verification time**: {sum of round durations}
             - **Final version**: INVESTIGATION_FINAL.md
             - **v2.2 Exit reason**: {CLEAN | SCOPE_ONLY_EXIT | CONVERGENCE}
             - **Auto-approve eligible**: {auto_approve_eligible}
             {% if continue_from != '' %}
             - **Mode**: Continuation from v{{starting_version}}
             - **Completeness weight**: 0.6 (reduced)
             {% endif %}
             ```
          
          6. STOP - verification complete
          
          **Step 9c: If MAX ROUNDS Reached or CONVERGENCE Detected**
          
          If completed round {{max_rounds}} with issues remaining OR convergence_detected:
          
          1. Create `{{output_dir}}/INVESTIGATION_FINAL.md` with appropriate header:
             
             If convergence_detected:
             ```markdown
             > ⚠️ **CONVERGENCE DETECTED**: Issues plateaued at ~{avg} for {{convergence_threshold}} rounds.
             > The verifiers may be finding scope suggestions rather than factual errors.
             > Review the Remaining Concerns section - these may be optional enhancements.
             ```
             
             If max rounds:
             ```markdown
             > ⚠️ **VERIFICATION INCOMPLETE**: Max rounds ({{max_rounds}}) reached with issues remaining.
             > Review the Remaining Concerns section carefully.
             ```
          
          2. Add "## Remaining Concerns" section with unfixed issues, classified by type:
             ```markdown
             ## Remaining Concerns
             
             ### Factual Issues (should be reviewed)
             [List any remaining factual issues]
             
             ### Scope Suggestions (optional)
             [List remaining scope/completeness suggestions]
             ```
          
          3. Update verification log noting exit reason
          4. Check auto-approve eligibility
          5. STOP - human will review (unless auto-approved)
          
          ## Output Format
          
          When complete, report:
          
          ```
          ## Verification Complete
          
          - **Result**: [VERIFIED CLEAN | SCOPE-ONLY EXIT | CONVERGENCE EXIT | MAX ROUNDS]
          - **Mode**: {% if continue_from != '' %}Continuation from v{{starting_version}}{% else %}Fresh{% endif %}
          - **Rounds completed**: {N}
          - **Total issues found/fixed**: {total}
          - **Factual issues**: {factual_total}
          - **Scope issues**: {scope_total}
          - **Final document**: {{output_dir}}/INVESTIGATION_FINAL.md
          
          ### v2.2 Exit Analysis
          - **Convergence detected**: {yes/no} (at round {N} if yes)
          - **Scope-only exit**: {yes/no}
          - **Auto-approve eligible**: {yes/no}
          - **Exit reason**: {CLEAN | SCOPE_ONLY | CONVERGENCE | MAX_ROUNDS}
          
          ### Issue Attribution (All Rounds)
          | Agent | Issues Found | Type | % of Total |
          |-------|--------------|------|------------|
          | logic_verifier | X | factual | Y% |
          | lsp_verifier | X | factual | Y% |
          | flow_verifier | X | - | Y% |
          | completeness_verifier | X | scope | Y% |
          
          ### Convergence Analysis
          | Round | Total Issues | Factual | Scope | Δ from Prev |
          |-------|--------------|---------|-------|-------------|
          | 1 | N | F | S | - |
          | 2 | N | F | S | ±X |
          | ... | ... | ... | ... | ... |
          
          ### Round Summary
          | Round | Tier | Duration | Issues | Factual | Scope | Agents Active |
          |-------|------|----------|--------|---------|-------|---------------|
          | 1 | Standard | Xs | N | F | S | 4 |
          | ... | ... | ... | ... | ... | ... | ... |
          
          ### Timing Metrics
          - Investigation phase: {% if continue_from != '' %}SKIPPED (continuation mode){% else %}Xs{% endif %}
          - Verification phase: Xs
          - Total time: Xs
          ```
        output: "verification_result"
        timeout: 3600  # 1 hour

  # ===========================================================================
  # STAGE 4: FINAL REVIEW (Human Approval Gate with Auto-Approve)
  # ===========================================================================
  - name: final_review
    description: |
      Human review of the verified document before final acceptance.
      
      v2.2: Can be auto-approved if conditions are met:
      - Total issues ≤ auto_approve_threshold
      - Factual verifiers (LSP, logic) were clean
      - No CRITICAL severity issues
    approval_required: true
    
    # v2.2: Auto-approve conditions
    # The approval gate will be skipped if these conditions are met
    auto_approve_if:
      # All conditions must be true for auto-approval
      - "{{verification_result}} contains 'Auto-approve eligible: yes'"
      - "{{auto_approve_threshold}} > 0"
    
    approval_message: |
      ## 🔍 Adversarial Deep Dive Complete (v2.2)
      
      **Topic**: {{topic}}
      
      {% if continue_from != '' %}
      **Mode**: CONTINUATION from `{{continue_from}}` (v{{starting_version}})
      - Completeness verifier weight reduced to 0.6 (from 1.2)
      {% else %}
      **Mode**: Fresh investigation
      {% endif %}
      
      ### Verification Result
      {{verification_result}}
      
      ### v2.2 Exit Analysis
      
      Check the verification result above for:
      - **Convergence detected?** - Issues may have plateaued (scope vs factual)
      - **Scope-only exit?** - Document is factually verified, scope suggestions optional
      - **Auto-approve eligible?** - Factual verifiers clean, low issue count
      
      ### Documents Created
      - `{{output_dir}}/INVESTIGATION_FINAL.md` - The verified document
      - `{{output_dir}}/verification-log.md` - Complete verification history
      - `{{output_dir}}/metrics.json` - Performance metrics with v2.2 fields
      - `{{output_dir}}/INVESTIGATION_v*.md` - All version files
      
      ### What to Review
      1. **Read the final document** - Does it accurately answer your question?
      2. **Check verification log** - Were the corrections sensible?
      3. **Review convergence analysis** - Did issues plateau? Are remaining issues scope suggestions?
      4. **If scope-only exit** - Are the skipped scope suggestions actually needed?
      5. **If convergence exit** - Are remaining issues factual errors or scope expansion?
      {% if continue_from != '' %}
      6. **Continuation check** - Did additional rounds improve the document?
      {% endif %}
      
      ---
      
      **APPROVE** to accept the investigation as complete and verified.
      
      **DENY** with feedback to request additional verification or changes.
    
    steps:
      - id: present_final
        type: bash
        command: |
          echo "╔════════════════════════════════════════════════════════════════╗"
          echo "║       ADVERSARIAL DEEP DIVE - FINAL DOCUMENT (v2.2)            ║"
          echo "╚════════════════════════════════════════════════════════════════╝"
          echo ""
          {% if continue_from != '' %}
          echo "MODE: Continuation from {{continue_from}} (v{{starting_version}})"
          echo "COMPLETENESS WEIGHT: 0.6 (reduced from 1.2)"
          echo ""
          {% endif %}
          cat "{{output_dir}}/INVESTIGATION_FINAL.md"
          echo ""
          echo "╔════════════════════════════════════════════════════════════════╗"
          echo "║                    VERIFICATION LOG                            ║"
          echo "╚════════════════════════════════════════════════════════════════╝"
          echo ""
          cat "{{output_dir}}/verification-log.md"
          echo ""
          echo "╔════════════════════════════════════════════════════════════════╗"
          echo "║                    METRICS (v2.2)                              ║"
          echo "╚════════════════════════════════════════════════════════════════╝"
          echo ""
          cat "{{output_dir}}/metrics.json"
      
      - id: generate_summary
        agent: self
        prompt: |
          # Generate Final Summary (v2.2)
          
          Create a concise summary for the user:
          
          ## Investigation Complete: {{topic}}
          
          {% if continue_from != '' %}
          **Mode**: Continuation from `{{continue_from}}` (started at v{{starting_version}})
          - Completeness verifier weight: 0.6 (reduced to prevent scope creep)
          {% else %}
          **Mode**: Fresh investigation
          {% endif %}
          
          ### Result
          {{verification_result}}
          
          ### Files Generated
          Location: `{{output_dir}}/`
          
          | File | Description |
          |------|-------------|
          | `INVESTIGATION_FINAL.md` | The verified document |
          | `verification-log.md` | Round-by-round history with agent attribution |
          | `metrics.json` | Performance and timing data with v2.2 fields |
          | `INVESTIGATION_v*.md` | All intermediate versions |
          
          ### Verification Process (v2.2)
          
          This document was verified through adversarial testing:
          
          | Verifier | Focus | Weight | Type |
          |----------|-------|--------|------|
          | LSP Verifier | Code accuracy, call chains, types | 1.0 | Factual |
          | Flow Verifier | Sequence, data flow, completeness | 1.0 | - |
          | Logic Verifier | Logical errors, inconsistencies | 1.5 ⭐ | Factual |
          | Completeness Verifier | Missing information, omissions | {% if continue_from != '' %}0.6{% else %}1.2{% endif %} | Scope |
          
          ### v2.2 Features Applied
          {% if continue_from != '' %}
          - ✅ **CONTINUATION MODE**: Resumed from v{{starting_version}}
          - ⏭️ Skipped pre-check, investigation, and synthesis stages
          - 📉 **Reduced completeness weight**: 0.6 (prevents scope creep)
          {% else %}
          - ✅ Pre-check validated inputs before investigation
          - ✅ Confidence tagging reduced false claims
          {% endif %}
          - ✅ **Convergence detection**: Auto-exit if issues plateau (threshold: {{convergence_threshold}})
          - ✅ **Scope-aware exit**: Exit if only scope issues remain
          - ✅ **Auto-approve**: Skip human review if factual verifiers clean
          - ✅ Real escalation tiers increased scrutiny each round
          - ✅ Structured verdicts enabled reliable parsing
          - ✅ Cross-visibility let verifiers learn from each other
          - ✅ Per-agent attribution tracked issue sources
          - ✅ Factual vs scope issue classification
          
          The document represents our best verified understanding of: **{{topic}}**
        output: "final_summary"
